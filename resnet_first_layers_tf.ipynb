{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_first_layers_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasirHabib/Deep-Learning-Advanced-Computer-Vision/blob/master/resnet_first_layers_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiKcOmw23Z26",
        "colab_type": "code",
        "outputId": "b8e97e79-5a0f-4172-8ab5-cc17023adb1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy the link and remove the front part of the link (i.e. https://drive.google.com/open?id=) to get the file ID.\n",
        "your_module = drive.CreateFile({'id':'1VwKqcBIeZjyeEGfC7oVd_kifRAoPoMNP'})\n",
        "your_module.GetContentFile('conv_block_tf.ipynb')\n",
        "from conv_block_tf import ConvLayer, BatchNormLayer, ConvBlock"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxjdUKH85i9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjJSa4au5lwt",
        "colab_type": "code",
        "outputId": "a45b5ba6-dad6-4ef9-b152-7b0c7f8f79de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# NOTE: dependent on your Keras version\n",
        "#       this script used 2.1.1\n",
        "# [<keras.engine.topology.InputLayer at 0x112fe4358>,\n",
        "#  <keras.layers.convolutional.Conv2D at 0x112fe46a0>,\n",
        "#  <keras.layers.normalization.BatchNormalization at 0x112fe4630>,\n",
        "#  <keras.layers.core.Activation at 0x112fe4eb8>,\n",
        "#  <keras.layers.pooling.MaxPooling2D at 0x10ed4be48>,\n",
        "#  <keras.layers.convolutional.Conv2D at 0x1130723c8>,\n",
        "#  <keras.layers.normalization.BatchNormalization at 0x113064710>,\n",
        "#  <keras.layers.core.Activation at 0x113092dd8>,\n",
        "#  <keras.layers.convolutional.Conv2D at 0x11309e908>,\n",
        "#  <keras.layers.normalization.BatchNormalization at 0x11308a550>,\n",
        "#  <keras.layers.core.Activation at 0x11312ac88>,\n",
        "#  <keras.layers.convolutional.Conv2D at 0x1131207b8>,\n",
        "#  <keras.layers.convolutional.Conv2D at 0x1131b8da0>,\n",
        "#  <keras.layers.normalization.BatchNormalization at 0x113115550>,\n",
        "#  <keras.layers.normalization.BatchNormalization at 0x1131a01d0>,\n",
        "#  <keras.layers.merge.Add at 0x11322f0f0>,\n",
        "#  <keras.layers.core.Activation at 0x113246cf8>]\n",
        "\n",
        "\n",
        "# define some additional layers so they have a forward function\n",
        "class ReLULayer:\n",
        "  def forward(self, X):\n",
        "    return tf.nn.relu(X)\n",
        "\n",
        "  def get_params(self):\n",
        "    return []\n",
        "\n",
        "class MaxPoolLayer:\n",
        "  def __init__(self, dim):\n",
        "    self.dim = dim\n",
        "\n",
        "  def forward(self, X):\n",
        "    return tf.nn.max_pool(\n",
        "      X,\n",
        "      ksize=[1, self.dim, self.dim, 1],\n",
        "      strides=[1, 2, 2, 1],\n",
        "      padding='VALID'\n",
        "    )\n",
        "\n",
        "  def get_params(self):\n",
        "    return []\n",
        "\n",
        "class PartialResNet:\n",
        "  def __init__(self):\n",
        "    self.layers = [\n",
        "      # before conv block\n",
        "      ConvLayer(64, 3, 7, 7, stride=2, padding='SAME'),\n",
        "      BatchNormLayer(64),\n",
        "      ReLULayer(),\n",
        "      MaxPoolLayer(dim=3),\n",
        "      # conv block\n",
        "      ConvBlock(num_color_channels=64, fm_sizes=[64, 64, 256])]\n",
        "    \n",
        "    self.input_ = tf.placeholder(tf.float32, shape=(None, 224, 224, 3))\n",
        "    self.output = self.forward(self.input_)\n",
        "\n",
        "  def copyFromKerasLayers(self, layers):\n",
        "    self.layers[0].copyFromKerasLayers(layers[1])\n",
        "    self.layers[1].copyFromKerasLayers(layers[2])\n",
        "    self.layers[4].copyFromKerasLayers(layers[5:])\n",
        "\n",
        "  def forward(self, X):\n",
        "    for layer in self.layers:\n",
        "      X = layer.forward(X)\n",
        "    return X\n",
        "\n",
        "  def predict(self, X):\n",
        "    assert(self.session is not None)\n",
        "    return self.session.run(\n",
        "      self.output,\n",
        "      feed_dict={self.input_: X}\n",
        "    )\n",
        "\n",
        "  def set_session(self, session):\n",
        "    self.session = session\n",
        "    self.layers[0].session = session\n",
        "    self.layers[1].session = session\n",
        "    self.layers[4].set_session(session)\n",
        "\n",
        "  def get_params(self):\n",
        "    params = []\n",
        "    for layer in self.layers:\n",
        "      params += layer.get_params()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # you can also set weights to None, it doesn't matter\n",
        "  resnet = ResNet50(weights='imagenet')\n",
        "\n",
        "  # you can determine the correct layer\n",
        "  # by looking at resnet.layers in the console\n",
        "  partial_model = Model(\n",
        "    inputs=resnet.input,\n",
        "    outputs=resnet.layers[16].output\n",
        "  )\n",
        "  print(partial_model.summary())\n",
        "  # for layer in partial_model.layers:\n",
        "  #   layer.trainable = False\n",
        "\n",
        "  my_partial_resnet = PartialResNet()\n",
        "\n",
        "  # make a fake image\n",
        "  X = np.random.random((1, 224, 224, 3))\n",
        "\n",
        "  # get keras output\n",
        "  keras_output = partial_model.predict(X)\n",
        "\n",
        "  # get my model output\n",
        "  init = tf.variables_initializer(my_partial_resnet.get_params())\n",
        "\n",
        "  # note: starting a new session messes up the Keras model\n",
        "  session = keras.backend.get_session()\n",
        "  my_partial_resnet.set_session(session)\n",
        "  session.run(init)\n",
        "\n",
        "  # first, just make sure we can get any output\n",
        "  first_output = my_partial_resnet.predict(X)\n",
        "  print(\"first_output.shape:\", first_output.shape)\n",
        "\n",
        "  # copy params from Keras model\n",
        "  my_partial_resnet.copyFromKerasLayers(partial_model.layers)\n",
        "\n",
        "  # compare the 2 models\n",
        "  output = my_partial_resnet.predict(X)\n",
        "  diff = np.abs(output - keras_output).sum()\n",
        "  if diff < 1e-10:\n",
        "    print(\"Everything's great!\")\n",
        "  else:\n",
        "    print(\"diff = %s\" % diff)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 230, 230, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
            "_________________________________________________________________\n",
            "bn_conv1 (BatchNormalization (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_148 (Activation)  (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)    (None, 114, 114, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "res2a_branch1 (Conv2D)       (None, 56, 56, 256)       16640     \n",
            "_________________________________________________________________\n",
            "bn2a_branch1 (BatchNormaliza (None, 56, 56, 256)       1024      \n",
            "=================================================================\n",
            "Total params: 27,392\n",
            "Trainable params: 26,752\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-90696dc9c89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;31m#   layer.trainable = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0mmy_partial_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPartialResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;31m# make a fake image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-90696dc9c89b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcopyFromKerasLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-90696dc9c89b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ConvBlock' object has no attribute 'forward'"
          ]
        }
      ]
    }
  ]
}